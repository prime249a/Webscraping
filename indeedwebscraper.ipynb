{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting page 0\n",
      "Getting page 10\n",
      "Getting page 20\n",
      "Getting page 30\n",
      "Getting page 40\n",
      "Getting page 50\n",
      "Getting page 60\n",
      "Getting page 70\n",
      "Getting page 80\n",
      "Getting page 90\n",
      "Getting page 100\n",
      "Getting page 110\n",
      "Getting page 120\n",
      "Getting page 130\n",
      "Getting page 140\n",
      "Getting page 150\n",
      "Getting page 160\n",
      "Getting page 170\n"
     ]
    }
   ],
   "source": [
    "def extract(page):\n",
    "    URL = f'https://ie.indeed.com/jobs?q=sql%20excel%20tableau&start={page}&vjk=97e6cfc952416d52'\n",
    "    headers = 'User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/102.0.0.0 Safari/537.36'\n",
    "    page = requests.get(URL, headers)\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    return soup\n",
    "\n",
    "def transform(soup):\n",
    "    jobs = soup.find_all('div', class_='job_seen_beacon')\n",
    "    for item in jobs:\n",
    "        company = item.find('span', class_='companyName').text\n",
    "        name = item.find('div', class_='heading4 color-text-primary singleLineTitle tapItem-gutter').text\n",
    "        location = item.find('div', class_='companyLocation').text\n",
    "        date = item.find('span', class_='date').text[6:]\n",
    "        try:\n",
    "            rating = item.find('span', class_='ratingsDisplay withRatingLink').text #could be absent\n",
    "        except:\n",
    "            rating = ''\n",
    "        try:\n",
    "            salary = item.find('div', class_='metadata salary-snippet-container').text #could be absent\n",
    "        except:\n",
    "            salary = ''\n",
    "\n",
    "        job = {\n",
    "            'name': name,\n",
    "            'company': company,\n",
    "            'location': location,\n",
    "            'rating': rating,\n",
    "            'salary': salary,\n",
    "            'date': date\n",
    "        }\n",
    "        joblist.append(job)\n",
    "\n",
    "joblist = []\n",
    "for i in range(0, 180, 10):\n",
    "    print(f'Getting page {i}')\n",
    "    c = extract(0)\n",
    "    transform(c)\n",
    "\n",
    "df = pd.DataFrame(joblist)\n",
    "\n",
    "df.to_csv('indeedscraped.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "492de5c55b0784f5394852be3d129468b1a3cbd17c8e16230d794b01878ae870"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
